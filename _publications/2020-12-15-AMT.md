---
title: "Amazon SageMaker Automatic Model Tuning: Scalable Black-box Optimization"
collection: publications
permalink: /publication/2020-12-15-AMT
date: 2020-12-15
venue: 'arXiv'
paperurl: 'https://arxiv.org/pdf/2012.08489'
citation: 'Valerio Perrone, <b>Huibin Shen</b>, Aida Zolic, Iaroslav Shcherbatyi, Amr Ahmed, Tanya Bansal, Michele Donini, Fela Winkelmolen, Rodolphe Jenatton, Jean Baptiste Faddoul, Barbara Pogorzelska, Miroslav Miladinovic, Krishnaram Kenthapadi, Matthias Seeger, CÃ©dric Archambeau. (2020). &quot;Amazon SageMaker Automatic Model Tuning: Scalable Black-box Optimization&quot; <i>arXiv preprint arXiv:2012.08489</i>'
---



## Abstract
Tuning complex machine learning systems is challenging. Machine learning models typically expose a set of
hyperparameters, be it regularization, architecture, or optimization parameters, whose careful tuning is critical to
achieve good performance. To democratize access to such systems, it is essential to automate this tuning process.
This paper presents Amazon SageMaker Automatic Model Tuning (AMT), a fully managed system for black-box
optimization at scale. AMT finds the best version of a machine learning model by repeatedly training it with
different hyperparameter configurations. It leverages either random search or Bayesian optimization to choose the
hyperparameter values resulting in the best-performing model, as measured by the metric chosen by the user. AMT
can be used with built-in algorithms, custom algorithms, and Amazon SageMaker pre-built containers for machine
learning frameworks. We discuss the core functionality, system architecture and our design principles. We also
describe some more advanced features provided by AMT, such as automated early stopping and warm-starting,
demonstrating their benefits in experiments.

Links: [[pdf]](https://arxiv.org/pdf/2012.08489.pdf) [[arXiv]](https://arxiv.org/pdf/2012.08489)